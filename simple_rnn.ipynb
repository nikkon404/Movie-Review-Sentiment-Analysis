{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87e60a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d9562f",
   "metadata": {},
   "source": [
    "Load the IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a1f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_size = 10000  # Limit the vocabulary size\n",
    "(X_train, y_train), (X_test,y_test) = imdb.load_data(num_words=max_vocab_size)\n",
    "\n",
    "# print the shape of the data\n",
    "print(f\"Training data shape: {X_train.shape}, Labels shape: {y_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}, Labels shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0b4e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the first review and its label\n",
    "sample_review = X_train[0]\n",
    "sample_label = y_train[0]\n",
    "\n",
    "print(f\"Sample review (encoded): {sample_review}\")\n",
    "print(f\"Sample label: {sample_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc231829",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  just for our understanding, let's map the words index to words\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "#  reverse the word index to get words from indices\n",
    "reverse_word_index = {value: key for key, value in word_index.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e7c3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index.get(1, '?')  # 1 is reserved for padding, so we can ignore it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29c5973",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_review\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69020791",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  now decode the sample review\n",
    "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in sample_review])\n",
    "print(f\"Decoded review: {decoded_review}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a12ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 500  # Maximum length of each review\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d0510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Train a simple RNN model\n",
    "model = Sequential()\n",
    "feature_dim = 128  # Dimension of the embedding space\n",
    "\n",
    "# embedding layer\n",
    "model.add(\n",
    "    Embedding(max_vocab_size, feature_dim, input_length=max_length)\n",
    ")\n",
    "\n",
    "model.add(SimpleRNN(128,activation='relu'))\n",
    "\n",
    "# for one output add a single Dense layer with sigmoid activation\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8031fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b92509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2f9b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Early stopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fd54e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model with early stopping\n",
    "#  THIS WILL TAKE A LONG TIME TO RUN - depending on your hardware\n",
    "history=model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46baf29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  now export the model\n",
    "model.save('simple_rnn_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
